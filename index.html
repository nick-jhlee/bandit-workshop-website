<!DOCTYPE html>
<html lang="en">
   
<head>
    <meta charset="utf-8" />
        
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <meta name="description" content="" />
    <meta name="author" content="" />
    <meta property="og:title" content="AI Safety Colloquium">
    <meta property="og:image" content="image/colloq.png">

    <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="css/styles.css" rel="stylesheet" />
    <link href="https://fonts.googleapis.com/css?family=Roboto:300,400&display=swap" rel="stylesheet">

    <link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500&display=swap" rel="stylesheet">

    <link href="https://fonts.googleapis.com/css?family=Source+Serif+Pro:400,600&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="css/bootstrap.min.css">

    <!-- Mathjax (LaTex support) -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
      </script>
      <script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
      </script>
          
    <!-- Style -->
    <link rel="stylesheet" href="css/button_style.css">
    <title>1st Korean AI Theory Community Workshop: Bandits</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f5f5f5;
        }
        .container {
            width: 100%;
            margin: 5px auto;
            background-color: #fff;
            padding: 20px;
            border-radius: 20px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            
        }
        .contact {
            background-color: #d4e1f7;
            padding: 10px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            margin-top: 20px;
            margin-bottom: 10px;
        }
        .session-box {
            background-color: #fff;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            margin-top: 20px;
            margin-bottom: 20px;
        }
        .session-info {
            margin-bottom: 20px;
        }
        .double-line {
            border-top: 3px double black;
        }
        .footer {
            text-align: center;
        }
        h1, h2 {
            text-align: center;
        }
        h3 {
            color: #0d6efd;
            font-size: 1.1rem;
            font-weight: 1000;
        }
        h4 {
            color: #000000;
            font-size: 1.1rem;
            font-weight: 1000;
        }
        h5 {
            color: #000000;
            font-size: 0.8rem;
            font-weight: 800;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 50px;
        }
        th, td {
            padding: 10px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #f2f2f2;
        }
        
        /* Make table responsive */
        @media (max-width: 600px) {
                table {
                    display: block;
                    overflow-x: auto;
                }
            }
    </style>
</head>
<body id="page-top">
    <!-- Navigation-->
    <!-- <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav"> -->
        <!-- <div class="container-lg px-5"> -->
            <!-- <a class="navbar-brand" href="https://kim-minseon.github.io/colloquium">Colloquium</a> -->
            <!-- <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button> -->
            <!-- <div class="collapse navbar-collapse" id="navbarResponsive"> -->
                <!-- <ul class="navbar-nav ms-auto"> -->
                    <!-- <li class="nav-item"><a class="nav-link" href="https://nick-jhlee.github.io/">Organizer</a></li> -->
                <!-- </ul> -->
            <!-- </div> -->
        <!-- </div> -->
    <!-- </nav> -->
    <div class="container">
        <header class="bg-primary bg-gradient text-white">
            <div class="container-lg px-5 text-center">
                <h1 class="fw-bolder">1st Korean AI Theory Community Workshop: Bandits</h1>
            </div>
        </header>
        <h1>Introduction</h1>
        This (student-led) workshop is motivated by the desire to build a solid, theory community amongst Korean researchers, either located in Korea or abroad, working in mathematical and theoretical AI.
            As the <i>first</i> edition, this workshop focuses on <b>bandits</b>.
            The workshop will feature six talks by leading emerging Korean researchers in the field, along with lunch, coffees and networking opportunities. The workshop is open to all researchers and students with an interest in bandits and related topics.
        <h1>Logistics</h1>
        The workshop will be held entirely in <i>Korean</i>.
        The location is KAIST Seoul Campus, Room 1114 (Kim Dong-Myoung Lecture Room).
        <!-- You are free to attend the workshop, but you will have to take care of lunch on your own if you haven't registered. -->
        <!-- <s>If you are interested in attending, please fill this <a href="https://forms.gle/CcDUj8XtF2HrrUDo8">Google Form</a> out ASAP!</s> -->
        If you are interested in attending, please fill this <a href="https://forms.gle/CcDUj8XtF2HrrUDo8">Google Form</a> out <b>by 06.17 (Mon)</b> for lunch and coffees!
        <br>
        For <b>speakers</b>:
        <ul>
            <li>Each talk should last <b>40min</b> in total (free to use however you want, ending early is also an option)</li>
            <li>Preferably, 30min presentation + 10min QnA/discussions</li>
        </ul>

        For <b>chairs</b>:
        <ul>
            <li> Introduce the speaker & facilitate QnA + discussions for each talk</li>
            <li>Each session should last <b>1h 30min</b> in total</li>
        </ul>

        <br>
        <h1>Workshop Schedule (2024.06.20)</h1>
<table>
    <thead>
        <tr>
            <th width="15%">Timeslot</th>
            <th>Speaker</th>
            <th width="68%">Schedule/Topic of the Talk</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>09:30 - 10:20</td>
            <td colspan="2"><b>Free Networking, Coffee Break</b></td>
            <td></td>
        </tr>
        <tr>
            <td>10:20 - 10:30</td>
            <td><b><a href="https://nick-jhlee.github.io/">Junghyun Lee</a></b><br>PhD Student<br><a href="https://gsai.kaist.ac.kr/">KAIST AI</a></td>
            <td><b>Opening Remarks</b></td>
        </tr>
        <tr class="double-line session-header">
            <td colspan="3"><b>Session #1. (Chair: Se-Young Yun)</b></td>
        </tr>
        <tr>
            <td>10:30 - 11:10</td>
            <td><b><a href="https://dabeenl.github.io/">Dabeen Lee</a></b><br>Assistant Professor<br><a href="https://ie.kaist.ac.kr/">KAIST ISysE</a></td>
            <td><h3>TBD</h3></td>
        </tr>
        <tr>
            <td>11:10 - 11:20</td>
            <td><b>Short Break</b></td>
            <td></td>
        </tr>
        <tr>
            <td>11:20 - 12:00</td>
            <td><b><a href="https://sites.google.com/view/yeoneung527">Yeoneung Kim</a></b><br>Assistant Professor<br><a href="https://aai.seoultech.ac.kr/en/">SeoulTech AAI</a></td>
            <td><h3>Approximate Thompson Sampling for Learning Linear Quadratic Regulators with $O(\sqrt{T})$ Regret</h3></td>
        </tr>
        <tr class="double-line session-header">
            <td>12:00 - 14:00</td>
            <td colspan="2"><b>Lunchtime + Coffee + Free Discussions</b><br>(<b>Lunch:</b> 교직원식당 @KAIST Seoul Campus — <i>예약예정</i>)</td>
        </tr>
        <tr class="double-line session-header">
            <td colspan="3"><b>Session #2. (Chair: Min-hwan Oh)</b></td>
        </tr>
        <tr>
            <td>14:00 - 14:40</td>
            <td><b><a href="https://kwangsungjun.github.io/index.html">Kwang-Sung Jun</a></b><br>Assistant Professor<br><a href="https://cs.arizona.edu/">Univ. of Arizona CS</a></td>
            <td><h3>Noise-Adaptive Confidence Sets for Linear Bandits</h3></td>
        </tr>
        <tr>
            <td>14:40 - 14:50</td>
            <td><b>Short Break</b></td>
            <td></td>
        </tr>
        <tr>
            <td>14:50 - 15:30</td>
            <td><b><a href="http://osi.kaist.ac.kr/">Se-Young Yun</a></b><br>Associate Professor<br><a href="https://gsai.kaist.ac.kr/">KAIST AI</a></td>
            <td><h3>From Logistic Bandits to Generalized Linear Bandits: Journey on Improving $S$-dependency</h3>
            </td>
        </tr>
        <tr class="double-line session-header">
            <td>15:30 - 16:00</td>
            <td><b>Long (Coffee) break</b></td>
            <td></td>
        </tr>
        <tr class="double-line session-header">
            <td colspan="3"><b>Session #3. (Chair: Dabeen Lee)</b></td>
        </tr>
        <tr>
            <td>16:00 - 16:40</td>
            <td><b><a href="https://minoh.io/">Min-hwan Oh</a></b><br>Assistant Professor<br><a href="https://gsds.snu.ac.kr/">SNU DS</a></td>
            <td><h3>Lasso Bandit with Compatibility Condition on Optimal Arm</h3></td>
        </tr>
        <tr>
            <td>16:40 - 16:50</td>
            <td><b>Short Break</b></td>
            <td></td>
        </tr>
        <tr>
            <td>16:50 - 17:30</td>
            <td><b><a href="https://sites.google.com/view/railab">Kyungjae Lee</a></b><br>Assistant Professor<br><a href="https://ai.cau.ac.kr/main.php">CAU AI</a></td>
            <td><h3>Optimal Algorithms for Multi-Armed Bandits with Heavy-Tailed Rewards</h3></td>
        </tr>
        <tr class="double-line session-header">
            <td>17:30 - 17:45</td>
            <td><b><a href="https://nick-jhlee.github.io/">Junghyun Lee</a></b><br>PhD Student<br><a href="https://gsai.kaist.ac.kr/">KAIST AI</a></td>
            <td><b>Closing Remarks</b></td>
        </tr>
    </tbody>
</table>

<br>
<h1>Speaker Bios & Talk Abstracts</h1>
        <div class="session-box">
            <div class="session-info">
                <h3>Talk #1 (Dabeen Lee): <a href="">TBD </a></h3>
            </div>
            <div class="speaker-bio">
                <h4>Speaker Bio:</h4>
                <p> Dabeen Lee is ... </p>
            </div>
            <div class="abstract">
                <h4>Abstract:</h4>
                <p> TBD.</p>
            </div>
        </div>

        <div class="session-box">
            <div class="session-info">
                <h3>Talk #2 (Yeoneung Kim): <a href="https://arxiv.org/abs/2405.19380">Approximate Thompson Sampling for Learning Linear Quadratic Regulators with $O(\sqrt{T})$ Regret </a></h3>
            </div>
            <div class="speaker-bio">
                <h4>Speaker Bio:</h4>
                <p> Yeoneung Kim is an Assistant Professor in the Department of Applied Artificial Intelligence at SeoulTech. 
                    He received a B.S. in Mathematics from POSTECH and a Ph.D. in Mathematics from the University of Wisconsin-Madison in 2011 and 2019. 
                    Before joining SeoulTech, he was a Researcher at the National Institute for Mathematical Sciences (2013 - 2016), 
                    a Staff Engineer at Samsung Electronics (2019-2021), a BK21 Postdoctoral Researcher at SNU (2021 - 2022), 
                    and an Assistant Professor in the Department of Financial Mathematics at Gachon University (2022-2023). 
                    His research focuses on optimal control and reinforcement learning. </p>
            </div>
            <div class="abstract">
                <h4>Abstract:</h4>
                <p>We propose an approximate Thompson sampling algorithm that learns linear quadratic regulators (LQR) with an improved Bayesian regret bound of $O(\sqrt{T})$.
                    Our method leverages Langevin dynamics with a meticulously designed preconditioner as well as a simple excitation mechanism.
                    We show that the excitation signal induces the minimum eigenvalue of the preconditioner to grow over time, thereby accelerating the approximate posterior sampling process.
                    Moreover, we identify nontrivial concentration properties of the approximate posteriors generated by our algorithm.
                    These properties enable us to bound the moments of the system state and attain an $O(\sqrt{T})$ regret bound without the unrealistic restrictive assumptions on parameter sets that are often used in the literature.
                    <br>
                    This is joint work with Gihun Kim (SNU ECE) and Insoon Yang (SNU ECE), and is based on the recent preprint of the <a href="https://arxiv.org/abs/2405.19380">same title</a>.
                </p>
            </div>
        </div>

        <div class="session-box">
            <div class="session-info">
                <h3>Talk #3 (Kwang-Sung Jun): Noise-Adaptive Confidence Sets for Linear Bandits </h3>
            </div>
            <div class="speaker-bio">
                <h4>Speaker Bio:</h4>
                <p> Kwang-Sung Jun is an Assistant Professor in the Department of Computer Science at the University of Arizona.
                    His research interest is interactive machine learning, especially theoretical aspects of bandit problems, online learning, and confidence bounds. 
                </p>
            </div>
            <div class="abstract">
                <h4>Abstract:</h4>
                <p>Adapting to a priori unknown noise level is a very important but challenging problem in sequential decision-making 
                    as efficient exploration typically requires knowledge of the noise level, which is often loosely specified. 
                    We report significant progress in addressing this issue in linear bandits in two respects. 
                    First, we propose a novel confidence set that is `semi-adaptive' to the unknown sub-Gaussian parameter 
                    $\sigma^2_*$ where the confidence width w.r.t. the dimension d scales with $\sigma^2_*$ rather than the specified sub-Gaussian parameter $\sigma^2_0$ that can be much larger than $\sigma^2_*$. 
                    In particular, when the true noise level is zero, this leads to removing a factor of $\sqrt{d}$ from the confidence width and the regret bound when used for linear bandits. 
                    Second, for bounded rewards, we propose a novel variance-adaptive confidence set that has a much improved numerical performance upon prior art while removing unrealistic assumptions. 
                    We then apply this confidence set to develop, as we claim, the first practical variance-adaptive linear bandit algorithm via an optimistic approach, which is enabled by our novel regret analysis technique. 
                    Both of our confidence sets rely critically on `regret equality' from online learning. 
                    Our empirical evaluation in Bayesian optimization tasks shows that our algorithms demonstrate better or comparable performance compared to existing methods.
                    <br>
                    This is joint work with Jungtaek Kim (Univ. of Pittsburg) and is based on the recently accepted ICML'24 paper of the <a href="https://arxiv.org/abs/2402.07341">same title</a>.
                </p>
            </div>
        </div>

        <div class="session-box">
            <div class="session-info">
                <h3>Talk #4 (Se-Young Yun): From Logistic Bandits to Generalized Linear Bandits: Journey on Improving $S$-dependency</h3>
            </div>
            <div class="speaker-bio">
                <h4>Speaker Bio:</h4>
                <p> Se-Young Yun is an Associate Professor at the Graduate School of AI, KAIST, in Seoul, South Korea. 
                    He holds a Ph.D. in Electrical Engineering from KAIST in 2012, where he also completed his B.S in 2006 <em>summa cum laude</em>. 
                    Before joining KAIST, he was a researcher at KTH, Inria, Microsoft Research Cambridge, and Los Alamos National Lab.
                    His research focuses on machine learning, particularly on the dynamics of evolving knowledge, enhancing reasoning in small models, and improving instruction robustness. 
                    He has been recognized with multiple awards, including Outstanding Reviewer Award at NIPS 2016 and Best Paper Award at ACM MobiHoc 2013. </p>
            </div>
            <div class="abstract">
                <h4>Abstract:</h4>
                <p> 
                    TBD
                    <br>
                    This is joint work with Junghyun Lee (KAIST AI) and Kwang-Sung Jun (Univ. of Arizona CS), and is based on the following two papers:
                    <ul>
                        <li><a href="https://arxiv.org/abs/2310.18554">Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion</a> (AISTATS 2024)</li>
                        <li>A Unified Confidence Sequence for Generalized Linear Models, with Applications to Bandits (arXiv 2024)</li>
                    </ul>
                </p>
            </div>
        </div>

        <div class="session-box">
            <div class="session-info">
                <h3>Talk #5 (Min-hwan Oh): Lasso Bandit with Compatibility Condition on Optimal Arm </h3>
            </div>
            <div class="speaker-bio">
                <h4>Speaker Bio:</h4>
                <p> Min-hwan Oh is an Assistant Professor in the Graduate School of Data Science at Seoul National University. 
                    His research interests are in sequential decision making under uncertainty including bandit algorithms and reinforcement learning, statistical machine learning, and optimization. </p>
            </div>
            <div class="abstract">
                <h4>Abstract:</h4>
                <p>We study a stochastic sparse linear bandit problem where only a sparse subset of context features affects the expected reward function, i.e., the unknown reward parameter has sparse structure. 
                    In the existing Lasso bandit literature, the compatibility conditions together with additional diversity conditions on the context features are imposed to achieve regret bounds that only depend logarithmically on the ambient dimension $d$.
                    In this paper, we demonstrate that even without the additional diversity assumptions, the compatibility condition only on the optimal arm is sufficient to derive a regret bound that depends logarithmically on $d$, and our assumption is strictly weaker than those used in the lasso bandit literature under the single parameter setting. 
                    To our knowledge, the proposed algorithm requires the weakest assumptions among Lasso bandit algorithms under a single parameter setting that achieve $O(\mathrm{poly} \log dT)$ regret. 
                    This is a joint work with Harin Lee and Taehyun Hwang from SNU and is based on the recent preprint of the <a href="https://arxiv.org/abs/2406.00823">same title.</a></p>
            </div>
        </div>

        <div class="session-box">
            <div class="session-info">
                <h3>Talk #6 (Kyungjae Lee): Optimal Algorithms for Multi-Armed Bandits with Heavy-Tailed Rewards</h3>
            </div>
            <div class="speaker-bio">
                <h4>Speaker Bio:</h4>
                <p> Kyungjae Lee is currently an Assistant Professor in the Department of Artificial Intelligence at Chung-Ang University. 
                    His current research interests include multi-armed bandit, Bayesian optimization, reinforcement learning, and its application. </p>
            </div>
            <div class="abstract">
                <h4>Abstract:</h4>
                <p>In this presentation, we will explore significant advancements in multi-armed bandits with heavy-tailed rewards.
                    The first paper, <a href="https://proceedings.neurips.cc/paper/2020/hash/607bc9ebe4abfcd65181bfbef6252830-Abstract.html">"Optimal Algorithms for Stochastic Multi-Armed Bandits with Heavy-Tailed Rewards (NeurIPS 2020),"</a>
                    proposes an adaptive perturbation method combined with a p-robust estimator, offering both theoretical and empirical improvements over existing methods.
                    The second paper, <a href="https://ieeexplore.ieee.org/document/9893089">"Minimax Optimal Bandits for Heavy-Tail Rewards (TNNLS 2024),"</a> introduces a robust estimator and a perturbation-based exploration strategy that achieve minimax optimal regret bounds without prior knowledge of reward distribution bounds.
                    Recently, I extended these approaches to distributional settings, further enhancing their applicability and performance.
                </p>
            </div>
        </div>

        <!-- Add more session-box divs for additional sessions -->
        
    

    <div class="contact">
    <b>Organizer.</b>
    <p><a href="https://nick-jhlee.github.io/">Junghyun Lee</a> [jh_lee00@kaist.ac.kr]</p>
    <p>I am a PhD student at <a href="http://osi.kaist.ac.kr/">OSI Lab</a> and <a href="https://chulheeyun.github.io/">OptiML Lab</a> at KAIST AI with broad interests in <b>mathematical and theoretical AI</b>. 
        Some of my recent interests include obtaining tight statistical guarantees for interactive machine learning (RL, bandits), exploring fundamental concepts in statistics and probability theory, algorithmic fairness, deep learning theory from both optimization and statistical perspectives, and essentially any machine learning challenges necessitating mathematical analysis.
    <br> If you are interested in talking about anything (research, workshop, etc), feel free to contact me! Also, I'm planning to make this into a series of workshops! If you are interested, please let me know!</p>
    </div>
</div>


<div class="footer">
    <p>This website format is copied from the website of <a href="https://kim-minseon.github.io/colloquium.html">KAIST AI Safety Colloquium</a> organized by <a href="https://kim-minseon.github.io/">Minseon Kim</a>, to whom the organizer is indebted to.</p>
  </div>
</body>
</html>

